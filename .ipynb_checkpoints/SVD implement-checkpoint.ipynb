{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy.linalg import pinv\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential \n",
    "from keras.callbacks import TensorBoard,EarlyStopping\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import  seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X = U . Sigma . V^*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# least squares via SVD with pseudoinverse\n",
    "data = array([\n",
    "\t[0.05, 0.12],\n",
    "\t[0.18, 0.22],\n",
    "\t[0.31, 0.35],\n",
    "\t[0.42, 0.38],\n",
    "\t[0.5, 0.49],\n",
    "\t])\n",
    "X, y = data[:,0], data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((len(X), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00233226]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# least squares via SVD with pseudoinverse\n",
    "data = array([\n",
    "\t[0.05, 0.12],\n",
    "\t[0.18, 0.22],\n",
    "\t[0.31, 0.35],\n",
    "\t[0.42, 0.38],\n",
    "\t[0.5, 0.49],\n",
    "\t])\n",
    "X, y = data[:,0], data[:,1]\n",
    "X = X.reshape((len(X), 1))\n",
    "# calculate coefficients  # PINV 求解廣義的逆矩陣\n",
    "b = pinv(X).dot(y)\n",
    "print(b)\n",
    "# predict using coefficients\n",
    "yhat = X.dot(b)\n",
    "# plot data and predictions\n",
    "pyplot.scatter(X, y)\n",
    "pyplot.plot(X, yhat, color='red')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabets = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'DESCR', 'feature_names', 'data_filename', 'target_filename'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabets['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(diabets['data'],columns = diabets['feature_names'])\n",
    "y = pd.DataFrame(diabets['target'],columns = ['disease progression']) # Target为一年后患疾病的定量指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([x,y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(71, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(89, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(282,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(71,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(89,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data.drop(['disease progression'], axis=1)\n",
    "y = data['disease progression']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state= 123)\n",
    "\n",
    "display(\n",
    "      X_train.shape,\n",
    "      X_val.shape,\n",
    "      X_test.shape,\n",
    "      y_train.shape,\n",
    "      y_val.shape,\n",
    "      y_test.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelCompile():\n",
    "    K.clear_session() \n",
    "    gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    tf.keras.backend.set_session(sess)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=10, kernel_initializer='normal', activation='relu',name = 'IntermediateLayer'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def ModelFit(model, weights, epochs):\n",
    "    #class_weight = {0: 1., 1: 1525/2632}\n",
    "    model.set_weights(weights)\n",
    "    modelcallbacks = model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=1,\n",
    "        validation_data = (X_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=3, verbose=2, restore_best_weights=True)],\n",
    "        shuffle=True) #, class_weight=class_weight\n",
    "#     SummarizeHistory(modelcallbacks, UseValid=True)                                        \n",
    "    weights = model.get_weights() \n",
    "    return model, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "IntermediateLayer (Dense)    (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ModelCompile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 282 samples, validate on 71 samples\n",
      "Epoch 1/150\n",
      "282/282 [==============================] - 0s 439us/step - loss: 28557.4032 - val_loss: 31096.9569\n",
      "Epoch 2/150\n",
      "282/282 [==============================] - 0s 71us/step - loss: 28553.3648 - val_loss: 31092.3118\n",
      "Epoch 3/150\n",
      "282/282 [==============================] - 0s 71us/step - loss: 28548.7392 - val_loss: 31087.0551\n",
      "Epoch 4/150\n",
      "282/282 [==============================] - 0s 74us/step - loss: 28543.6474 - val_loss: 31081.1705\n",
      "Epoch 5/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 28537.9610 - val_loss: 31074.6528\n",
      "Epoch 6/150\n",
      "282/282 [==============================] - 0s 71us/step - loss: 28531.6122 - val_loss: 31067.4712\n",
      "Epoch 7/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 28524.5638 - val_loss: 31059.5704\n",
      "Epoch 8/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 28516.8240 - val_loss: 31050.9207\n",
      "Epoch 9/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 28508.3853 - val_loss: 31041.4076\n",
      "Epoch 10/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 28499.3656 - val_loss: 31030.9362\n",
      "Epoch 11/150\n",
      "282/282 [==============================] - 0s 71us/step - loss: 28489.3422 - val_loss: 31019.6973\n",
      "Epoch 12/150\n",
      "282/282 [==============================] - 0s 69us/step - loss: 28478.4789 - val_loss: 31007.7526\n",
      "Epoch 13/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 28466.8833 - val_loss: 30994.9571\n",
      "Epoch 14/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 28454.7143 - val_loss: 30981.0571\n",
      "Epoch 15/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 28441.5414 - val_loss: 30966.3150\n",
      "Epoch 16/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 28427.3538 - val_loss: 30950.8727\n",
      "Epoch 17/150\n",
      "282/282 [==============================] - 0s 69us/step - loss: 28412.8052 - val_loss: 30934.2844\n",
      "Epoch 18/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 28396.8766 - val_loss: 30917.0787\n",
      "Epoch 19/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 28380.7855 - val_loss: 30898.7493\n",
      "Epoch 20/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 28363.5412 - val_loss: 30879.5615\n",
      "Epoch 21/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 28345.3019 - val_loss: 30859.6565\n",
      "Epoch 22/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 28326.2840 - val_loss: 30838.9192\n",
      "Epoch 23/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 28306.9874 - val_loss: 30816.9147\n",
      "Epoch 24/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 28286.2154 - val_loss: 30794.3164\n",
      "Epoch 25/150\n",
      "282/282 [==============================] - 0s 71us/step - loss: 28264.6992 - val_loss: 30771.0202\n",
      "Epoch 26/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 28242.9782 - val_loss: 30746.4878\n",
      "Epoch 27/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 28219.7974 - val_loss: 30721.3018\n",
      "Epoch 28/150\n",
      "282/282 [==============================] - 0s 71us/step - loss: 28196.0709 - val_loss: 30695.2320\n",
      "Epoch 29/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 28171.3997 - val_loss: 30668.3733\n",
      "Epoch 30/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 28146.1909 - val_loss: 30640.4837\n",
      "Epoch 31/150\n",
      "282/282 [==============================] - 0s 71us/step - loss: 28120.3695 - val_loss: 30611.4658\n",
      "Epoch 32/150\n",
      "282/282 [==============================] - 0s 78us/step - loss: 28093.1952 - val_loss: 30581.8875\n",
      "Epoch 33/150\n",
      "282/282 [==============================] - 0s 74us/step - loss: 28065.7445 - val_loss: 30551.2766\n",
      "Epoch 34/150\n",
      "282/282 [==============================] - 0s 71us/step - loss: 28036.9133 - val_loss: 30520.2878\n",
      "Epoch 35/150\n",
      "282/282 [==============================] - 0s 71us/step - loss: 28007.6874 - val_loss: 30488.4671\n",
      "Epoch 36/150\n",
      "282/282 [==============================] - 0s 71us/step - loss: 27977.6919 - val_loss: 30455.7575\n",
      "Epoch 37/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 27947.3341 - val_loss: 30421.8310\n",
      "Epoch 38/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 27915.5610 - val_loss: 30387.4841\n",
      "Epoch 39/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 27883.5601 - val_loss: 30352.1451\n",
      "Epoch 40/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 27850.6174 - val_loss: 30315.9847\n",
      "Epoch 41/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 27816.9359 - val_loss: 30279.0785\n",
      "Epoch 42/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 27781.7082 - val_loss: 30242.0476\n",
      "Epoch 43/150\n",
      "282/282 [==============================] - 0s 57us/step - loss: 27747.2912 - val_loss: 30203.3038\n",
      "Epoch 44/150\n",
      "282/282 [==============================] - 0s 71us/step - loss: 27711.3418 - val_loss: 30163.8591\n",
      "Epoch 45/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 27674.7464 - val_loss: 30123.8031\n",
      "Epoch 46/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 27637.0889 - val_loss: 30083.3715\n",
      "Epoch 47/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 27599.6246 - val_loss: 30041.4930\n",
      "Epoch 48/150\n",
      "282/282 [==============================] - 0s 71us/step - loss: 27560.8098 - val_loss: 29998.9558\n",
      "Epoch 49/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 27520.5973 - val_loss: 29956.3570\n",
      "Epoch 50/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 27481.4525 - val_loss: 29911.9319\n",
      "Epoch 51/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 27439.5110 - val_loss: 29868.0062\n",
      "Epoch 52/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 27398.3958 - val_loss: 29822.7569\n",
      "Epoch 53/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 27356.2188 - val_loss: 29776.7299\n",
      "Epoch 54/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 27313.2036 - val_loss: 29730.0739\n",
      "Epoch 55/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 27269.6451 - val_loss: 29682.4438\n",
      "Epoch 56/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 27226.2805 - val_loss: 29633.2369\n",
      "Epoch 57/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 27180.8910 - val_loss: 29584.0665\n",
      "Epoch 58/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 27134.6351 - val_loss: 29535.0547\n",
      "Epoch 59/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 27089.1237 - val_loss: 29484.6898\n",
      "Epoch 60/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 27042.0736 - val_loss: 29433.8196\n",
      "Epoch 61/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 26995.2331 - val_loss: 29381.8530\n",
      "Epoch 62/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 26947.1930 - val_loss: 29329.2505\n",
      "Epoch 63/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 26897.6745 - val_loss: 29276.8908\n",
      "Epoch 64/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 26849.9421 - val_loss: 29222.4269\n",
      "Epoch 65/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 26798.8120 - val_loss: 29168.4886\n",
      "Epoch 66/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 26748.2471 - val_loss: 29113.9614\n",
      "Epoch 67/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 26697.8780 - val_loss: 29058.0694\n",
      "Epoch 68/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 26645.4657 - val_loss: 29001.9871\n",
      "Epoch 69/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 26593.7982 - val_loss: 28944.6633\n",
      "Epoch 70/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 26541.0909 - val_loss: 28886.5421\n",
      "Epoch 71/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 26486.6198 - val_loss: 28828.9467\n",
      "Epoch 72/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 26432.9190 - val_loss: 28770.4367\n",
      "Epoch 73/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 26379.6019 - val_loss: 28710.2614\n",
      "Epoch 74/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 64us/step - loss: 26323.7505 - val_loss: 28650.3888\n",
      "Epoch 75/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 26268.0195 - val_loss: 28589.7770\n",
      "Epoch 76/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 26211.8050 - val_loss: 28528.5827\n",
      "Epoch 77/150\n",
      "282/282 [==============================] - 0s 57us/step - loss: 26154.0120 - val_loss: 28467.3783\n",
      "Epoch 78/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 26098.4829 - val_loss: 28403.9447\n",
      "Epoch 79/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 26039.4181 - val_loss: 28341.3061\n",
      "Epoch 80/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 25980.8474 - val_loss: 28278.1870\n",
      "Epoch 81/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 25922.7779 - val_loss: 28213.6730\n",
      "Epoch 82/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 25862.3528 - val_loss: 28149.6440\n",
      "Epoch 83/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 25803.3827 - val_loss: 28084.0591\n",
      "Epoch 84/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 25742.8081 - val_loss: 28018.1324\n",
      "Epoch 85/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 25681.3212 - val_loss: 27952.3309\n",
      "Epoch 86/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 25620.6335 - val_loss: 27885.2005\n",
      "Epoch 87/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 25558.2488 - val_loss: 27817.8089\n",
      "Epoch 88/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 25495.5402 - val_loss: 27750.2096\n",
      "Epoch 89/150\n",
      "282/282 [==============================] - 0s 62us/step - loss: 25433.3528 - val_loss: 27681.3522\n",
      "Epoch 90/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 25369.5782 - val_loss: 27612.1758\n",
      "Epoch 91/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 25304.9300 - val_loss: 27543.4356\n",
      "Epoch 92/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 25241.9197 - val_loss: 27472.8084\n",
      "Epoch 93/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 25176.6009 - val_loss: 27402.4583\n",
      "Epoch 94/150\n",
      "282/282 [==============================] - 0s 59us/step - loss: 25111.3978 - val_loss: 27331.7081\n",
      "Epoch 95/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 25046.4503 - val_loss: 27259.8110\n",
      "Epoch 96/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 24979.3488 - val_loss: 27188.2970\n",
      "Epoch 97/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 24913.8602 - val_loss: 27115.3689\n",
      "Epoch 98/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 24846.0705 - val_loss: 27043.0342\n",
      "Epoch 99/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 24779.1535 - val_loss: 26969.7836\n",
      "Epoch 100/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 24711.0661 - val_loss: 26896.3151\n",
      "Epoch 101/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 24643.6266 - val_loss: 26821.5253\n",
      "Epoch 102/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 24574.8489 - val_loss: 26746.7682\n",
      "Epoch 103/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 24504.7820 - val_loss: 26672.5173\n",
      "Epoch 104/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 24435.7900 - val_loss: 26597.2214\n",
      "Epoch 105/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 24366.8839 - val_loss: 26520.6543\n",
      "Epoch 106/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 24296.2638 - val_loss: 26444.3901\n",
      "Epoch 107/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 24225.4427 - val_loss: 26367.8041\n",
      "Epoch 108/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 24154.5894 - val_loss: 26290.6231\n",
      "Epoch 109/150\n",
      "282/282 [==============================] - 0s 57us/step - loss: 24083.0892 - val_loss: 26213.3599\n",
      "Epoch 110/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 24012.6645 - val_loss: 26134.9028\n",
      "Epoch 111/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 23939.8854 - val_loss: 26057.0080\n",
      "Epoch 112/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 23868.0091 - val_loss: 25978.5120\n",
      "Epoch 113/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 23795.4019 - val_loss: 25899.7403\n",
      "Epoch 114/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 23721.9056 - val_loss: 25821.0519\n",
      "Epoch 115/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 23649.9110 - val_loss: 25740.8180\n",
      "Epoch 116/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 23575.3075 - val_loss: 25661.4927\n",
      "Epoch 117/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 23502.6721 - val_loss: 25580.5481\n",
      "Epoch 118/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 23428.2666 - val_loss: 25499.6786\n",
      "Epoch 119/150\n",
      "282/282 [==============================] - 0s 57us/step - loss: 23354.2002 - val_loss: 25418.4226\n",
      "Epoch 120/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 23278.0692 - val_loss: 25337.9741\n",
      "Epoch 121/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 23204.9947 - val_loss: 25255.3612\n",
      "Epoch 122/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 23127.9205 - val_loss: 25174.0775\n",
      "Epoch 123/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 23052.6452 - val_loss: 25092.1791\n",
      "Epoch 124/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 22977.5698 - val_loss: 25009.1951\n",
      "Epoch 125/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 22900.8203 - val_loss: 24926.4850\n",
      "Epoch 126/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 22824.5374 - val_loss: 24843.3054\n",
      "Epoch 127/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 22748.6829 - val_loss: 24759.1789\n",
      "Epoch 128/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 22671.1121 - val_loss: 24675.4365\n",
      "Epoch 129/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 22593.3161 - val_loss: 24592.2959\n",
      "Epoch 130/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 22516.3117 - val_loss: 24508.0947\n",
      "Epoch 131/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 22439.2970 - val_loss: 24422.9499\n",
      "Epoch 132/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 22361.6400 - val_loss: 24337.3464\n",
      "Epoch 133/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 22282.1101 - val_loss: 24253.3569\n",
      "Epoch 134/150\n",
      "282/282 [==============================] - 0s 74us/step - loss: 22204.7305 - val_loss: 24168.4621\n",
      "Epoch 135/150\n",
      "282/282 [==============================] - 0s 74us/step - loss: 22127.5501 - val_loss: 24082.5507\n",
      "Epoch 136/150\n",
      "282/282 [==============================] - 0s 71us/step - loss: 22047.6401 - val_loss: 23997.5563\n",
      "Epoch 137/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 21969.5301 - val_loss: 23911.6862\n",
      "Epoch 138/150\n",
      "282/282 [==============================] - 0s 74us/step - loss: 21890.3740 - val_loss: 23825.6811\n",
      "Epoch 139/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 21811.1330 - val_loss: 23739.6595\n",
      "Epoch 140/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 21732.3587 - val_loss: 23652.8337\n",
      "Epoch 141/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 21651.3913 - val_loss: 23567.1984\n",
      "Epoch 142/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 21573.1097 - val_loss: 23479.8097\n",
      "Epoch 143/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 21492.3821 - val_loss: 23393.0021\n",
      "Epoch 144/150\n",
      "282/282 [==============================] - 0s 67us/step - loss: 21412.1500 - val_loss: 23306.0560\n",
      "Epoch 145/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 21332.0373 - val_loss: 23218.6693\n",
      "Epoch 146/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 21250.2374 - val_loss: 23132.4565\n",
      "Epoch 147/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 64us/step - loss: 21172.4017 - val_loss: 23042.8288\n",
      "Epoch 148/150\n",
      "282/282 [==============================] - 0s 71us/step - loss: 21089.9779 - val_loss: 22954.6502\n",
      "Epoch 149/150\n",
      "282/282 [==============================] - 0s 60us/step - loss: 21007.6470 - val_loss: 22867.4476\n",
      "Epoch 150/150\n",
      "282/282 [==============================] - 0s 64us/step - loss: 20927.5453 - val_loss: 22778.8764\n"
     ]
    }
   ],
   "source": [
    "weights = model.get_weights() \n",
    "model, weights = ModelFit(model=model, weights=weights, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model as keras_models_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x26401e65278>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_models_Model(inputs=model.input,outputs=model.get_layer(layer_name).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.7046004e-02, -4.5516018e-02,  8.2084727e-01,  9.2510307e-01,\n",
       "          9.2393488e-01,  7.7926075e-01,  8.2876170e-01,  1.0172173e+00,\n",
       "          8.6725402e-01,  9.9616659e-01],\n",
       "        [-1.5500236e-02,  1.1723734e-03,  5.4647428e-01,  4.8597154e-01,\n",
       "          5.2680635e-01,  5.4592103e-01,  5.3486878e-01,  5.8376402e-01,\n",
       "          5.1221567e-01,  4.7823125e-01],\n",
       "        [-3.3527855e-02,  4.4681083e-02,  1.4950323e+00,  1.5056608e+00,\n",
       "          1.4156687e+00,  1.5934467e+00,  1.6307081e+00,  1.5488871e+00,\n",
       "          1.5864033e+00,  1.4323385e+00],\n",
       "        [-4.0574770e-02, -4.0371239e-02,  1.5793885e+00,  1.4340421e+00,\n",
       "          1.4569027e+00,  1.4747052e+00,  1.4521358e+00,  1.5277277e+00,\n",
       "          1.6199579e+00,  1.5541532e+00],\n",
       "        [-2.2589026e-02, -3.4565076e-02,  8.8126016e-01,  8.0241489e-01,\n",
       "          8.5303515e-01,  8.8963157e-01,  8.7272894e-01,  7.9099298e-01,\n",
       "          9.1461110e-01,  9.3052572e-01],\n",
       "        [ 2.0110475e-02,  1.1052767e-02,  7.7047271e-01,  7.4065757e-01,\n",
       "          7.3236698e-01,  9.2672586e-01,  8.7537670e-01,  7.3632127e-01,\n",
       "          8.0729842e-01,  7.6789308e-01],\n",
       "        [ 2.1007264e-02, -7.7053942e-02, -1.4458700e+00, -1.5253592e+00,\n",
       "         -1.4550220e+00, -1.4665467e+00, -1.5315164e+00, -1.5472684e+00,\n",
       "         -1.5764637e+00, -1.4296641e+00],\n",
       "        [ 3.8274564e-02,  1.0893863e-02,  1.3206189e+00,  1.2914549e+00,\n",
       "          1.2901881e+00,  1.2967763e+00,  1.4991201e+00,  1.3248519e+00,\n",
       "          1.3693458e+00,  1.4465982e+00],\n",
       "        [ 1.5839303e-02, -8.2975422e-04,  1.5261754e+00,  1.5203187e+00,\n",
       "          1.4794459e+00,  1.5565082e+00,  1.5836036e+00,  1.5374210e+00,\n",
       "          1.6194937e+00,  1.5567601e+00],\n",
       "        [-8.7248897e-03,  2.0706339e-02,  1.4496008e+00,  1.6083390e+00,\n",
       "          1.4791071e+00,  1.4633380e+00,  1.5630296e+00,  1.4182149e+00,\n",
       "          1.6208264e+00,  1.3951267e+00]], dtype=float32),\n",
       " array([-0.01267492, -0.01918187,  1.9740446 ,  1.9523463 ,  2.0215838 ,\n",
       "         2.020804  ,  2.026979  ,  2.0315964 ,  2.0349097 ,  2.0196004 ],\n",
       "       dtype=float32),\n",
       " array([[-0.0191355],\n",
       "        [-0.0191193],\n",
       "        [ 2.096881 ],\n",
       "        [ 2.1185007],\n",
       "        [ 2.060591 ],\n",
       "        [ 2.054659 ],\n",
       "        [ 2.0430098],\n",
       "        [ 2.0408545],\n",
       "        [ 2.0317068],\n",
       "        [ 2.0581186]], dtype=float32),\n",
       " array([1.2817289], dtype=float32)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_input  = weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,10) and (442,) not aligned: 10 (dim 1) != 442 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-c83ff7a2aeca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mreg_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# calculate coefficients  # PINV 求解廣義的逆矩陣\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpinv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,10) and (442,) not aligned: 10 (dim 1) != 442 (dim 0)"
     ]
    }
   ],
   "source": [
    "reg_input = reg_input.reshape((len(reg_input), 1))\n",
    "# calculate coefficients  # PINV 求解廣義的逆矩陣\n",
    "b = pinv(reg_input).dot(y)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using coefficients\n",
    "yhat = X.dot(b)\n",
    "# plot data and predictions\n",
    "pyplot.scatter(X, y)\n",
    "pyplot.plot(X, yhat, color='red')\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
